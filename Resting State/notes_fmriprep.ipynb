{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# create the singularity image on Argon\n",
    "\n",
    "SINGULARITY_TMPDIR=/Users/tientong/singularity_temp\n",
    "export SINGULARITY_TMPDIR\n",
    "singularity build /Users/tientong/singularity_home/fmriprep_20.1.3.simg docker://poldracklab/fmriprep:20.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fMRIPrep template files\n",
    "\n",
    "## Template for subject with fieldmap data\n",
    "\n",
    "```\n",
    "#!/bin/sh\n",
    "#$ -pe smp 20\n",
    "#$ -q UI,CCOM,all.q\n",
    "#$ -ckpt user\n",
    "#$ -o /Shared/tientong_scratch/abcd/code/derivative_logs/fmriprep\n",
    "#$ -e /Shared/tientong_scratch/abcd/code/derivative_logs/fmriprep\n",
    "OMP_NUM_THREADS=16\n",
    "singularity run -H /Users/tientong/singularity_home \\\n",
    "  /Users/tientong/fmriprep_20.1.3.simg \\\n",
    "  /Shared/tientong_scratch/abcd/rawdata \\\n",
    "  /Shared/tientong_scratch/abcd/derivatives/fmriprep \\\n",
    "  participant --participant-label SUBJECT \\\n",
    "  --fs-license-file /Shared/oleary/functional/FreeSurferLicense/license.txt \\\n",
    "  -w /Shared/tientong_scratch/abcd/derivatives/fmriprep --write-graph \\\n",
    "  --output-spaces T1w MNI152NLin6Asym:res-2 --stop-on-first-crash \\\n",
    "  --omp-nthreads 16 --nthreads 16 --mem 40 --notrack --fs-no-reconall \\\n",
    "  --skip_bids_validation --ignore slicetiming\n",
    "```\n",
    "\n",
    "## Template for subject without fieldmap data\n",
    "\n",
    "```\n",
    "#!/bin/sh\n",
    "#$ -pe smp 20\n",
    "#$ -q UI,CCOM,all.q\n",
    "#$ -ckpt user\n",
    "#$ -o /Shared/tientong_scratch/abcd/code/derivative_logs/fmriprep\n",
    "#$ -e /Shared/tientong_scratch/abcd/code/derivative_logs/fmriprep\n",
    "OMP_NUM_THREADS=16\n",
    "singularity run -H /Users/tientong/singularity_home \\\n",
    "  /Users/tientong/fmriprep_20.1.3.simg \\\n",
    "  /Shared/tientong_scratch/abcd/rawdata \\\n",
    "  /Shared/tientong_scratch/abcd/derivatives/fmriprep \\\n",
    "  participant --participant-label SUBJECT \\\n",
    "  --fs-license-file /Shared/oleary/functional/FreeSurferLicense/license.txt \\\n",
    "  -w /Shared/tientong_scratch/abcd/derivatives/fmriprep --write-graph \\\n",
    "  --output-spaces T1w MNI152NLin6Asym:res-2 --stop-on-first-crash \\\n",
    "  --omp-nthreads 16 --nthreads 16 --mem 40 --notrack --fs-no-reconall \\\n",
    "  --skip_bids_validation --ignore slicetiming fieldmaps --use-syn-sdc\n",
    "```\n",
    "\n",
    "## From those templates, create subject-specific fMRIPrep job script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "list=($(cat /Shared/tientong_scratch/abcd/derivatives/baw/randomhash_200725.txt))\n",
    "bidsdir=/Shared/tientong_scratch/abcd/rawdata\n",
    "template=/Shared/tientong_scratch/abcd/code/fmriprep/template\n",
    "script=/Shared/tientong_scratch/abcd/code/fmriprep/subject_scripts\n",
    "\n",
    "for i in ${!list[@]} ; do\n",
    " SUBJECT=(`echo ${list[$i]} | awk '{gsub(\"/\",\" \"); print $5}'| awk '{gsub(\"-\",\" \"); print $2}'`)\n",
    " SESSION=baselineYear1Arm1\n",
    " if [ -d ${bidsdir}/sub-${SUBJECT}/ses-${SESSION}/func ] &&\n",
    "    [ 0 -lt `ls ${bidsdir}/sub-${SUBJECT}/ses-${SESSION}/anat/*T1w*.nii.gz 2>/dev/null | wc -l` ] ; then\n",
    "  STR=$'\"IntendedFor\"\\: \\[$'\n",
    "  if [ -d ${bidsdir}/sub-${SUBJECT}/ses-${SESSION}/fmap ] &&\n",
    "     [ 0 -lt `grep -rnw ${bidsdir}/sub-${SUBJECT}/ses-${SESSION}/fmap -e \"$STR\" 2>/dev/null | wc -l` ] ; then\n",
    "    sed -e \"s|SUBJECT|${SUBJECT}|g\" ${template}/fmriprep_nostc_TEMPLATE.sh \\\n",
    "    > ${script}/sub-${SUBJECT}_ses-${SESSION}_fmriprep_nostc.sh\n",
    "    # qsub ${script}/sub-${SUBJECT}_ses-${SESSION}_fmriprep_nostc.sh\n",
    "  else\n",
    "    sed -e \"s|SUBJECT|${SUBJECT}|g\" ${template}/fmriprep_nostc_syn_TEMPLATE.sh \\\n",
    "    > ${script}/sub-${SUBJECT}_ses-${SESSION}_fmriprep_nostc_syn.sh\n",
    "    # qsub ${script}/sub-${SUBJECT}_ses-${SESSION}_fmriprep_nostc_syn.sh        \n",
    "  fi\n",
    " fi\n",
    "done\n",
    "\n",
    "\n",
    "##### 838 jobs - submitting 100 at once\n",
    "\n",
    "jobs=($(ls /Shared/tientong_scratch/abcd/code/fmriprep/subject_scripts/*))\n",
    "\n",
    "for i in $(seq 0 1 100) ; do\n",
    "  qsub ${jobs[$i]}\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delete intermediate files of subjects that completed fMRIPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# First delete the intermediate files for subjects with completed fmriprep\n",
    "\n",
    "template=/Shared/tientong_scratch/abcd/code/fmriprep/template\n",
    "fmriprepdir=/Shared/tientong_scratch/abcd/derivatives/fmriprep\n",
    "script=/Shared/tientong_scratch/abcd/code/fmriprep/subject_scripts\n",
    "logdir=/Shared/tientong_scratch/abcd/code/derivative_logs/fmriprep\n",
    "\n",
    "source /etc/profile.d/sge.sh\n",
    "\n",
    "cd $fmriprepdir/fmriprep\n",
    "finish=($(ls *.html))\n",
    "SUBJECT_finish=()\n",
    "for i in ${!finish[@]} ; do\n",
    "  SUBJECT_finish+=($(cut -d \".\" -f 1 <<<`echo ${finish[$i]}  | awk '{gsub(\"-\",\" \"); print $2}'`)) \n",
    "done\n",
    "cd\n",
    "for i in ${!SUBJECT_finish[@]} ; do\n",
    "  sed -e \"s|SUBJECT|${SUBJECT_finish[$i]}|g\" ${template}/delete.sh \\\n",
    "       > ${template}/sub-${SUBJECT_finish[$i]}_delete.sh\n",
    "  qsub ${template}/sub-${SUBJECT_finish[$i]}_delete.sh \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save this file as `/Users/tientong/cron_delete.sh` and run the shell below on Argon to run the script every hour using `crontab -e`\n",
    "\n",
    "```\n",
    "0 * * * * /Users/tientong/cron_delete.sh\n",
    "```\n",
    "\n",
    "Check to see if this is saved with `crontab -l`, and delete with `crontab -r`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fMRIPrep QC: Check for errors\n",
    "\n",
    "Jobs submitted to all.q will be kicked off but SHOULD be automatically resubmitted. However, in case there are errors in this process, find the subjects with errors, delete the fmriprep outputs for those subjects, and rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "template=/Shared/tientong_scratch/abcd/code/fmriprep/template\n",
    "fmriprepdir=/Shared/tientong_scratch/abcd/derivatives/fmriprep\n",
    "script=/Shared/tientong_scratch/abcd/code/fmriprep/subject_scripts\n",
    "logdir=/Shared/tientong_scratch/abcd/code/derivative_logs/fmriprep\n",
    "\n",
    "\n",
    "# Get an array of subjects who completed fmriprep\n",
    "\n",
    "cd $fmriprepdir/fmriprep\n",
    "finish=($(ls *.html))\n",
    "SUBJECT_finish=()\n",
    "for i in ${!finish[@]} ; do\n",
    "  SUBJECT_finish+=($(cut -d \".\" -f 1 <<<`echo ${finish[$i]}  | \\\n",
    "                     awk '{gsub(\"-\",\" \"); print $2}'`)) \n",
    "done\n",
    "cd\n",
    "\n",
    "# get an array of subjects need to be run\n",
    "subjectlist=($(cat /Shared/tientong_scratch/abcd/derivatives/baw/randomhash_200725.txt))\n",
    "SUBJECT_full=()\n",
    "for i in ${!subjectlist[@]} ; do\n",
    "  SUBJECT_full+=($(echo ${subjectlist[$i]} | \\\n",
    "                   awk '{gsub(\"/\",\" \"); print $5}'| \\\n",
    "                   awk '{gsub(\"-\",\" \"); print $2}'))\n",
    "done\n",
    "\n",
    "# get the difference between the completed list and to-run list\n",
    "SUBJECT=($(echo ${SUBJECT_full[@]} ${SUBJECT_finish[@]} | \\\n",
    "           tr ' ' '\\n' | sort | uniq -u))\n",
    "\n",
    "for i in ${!SUBJECT[@]} ; do\n",
    "  if [ -f $script/*${SUBJECT[$i]}* ] ; then\n",
    "     rm $logdir/*${SUBJECT[$i]}*\n",
    "     rm -rf $fmriprepdir/fmriprep/*${SUBJECT[$i]}*/*\n",
    "     rmdir $fmriprepdir/fmriprep/*${SUBJECT[$i]}*\n",
    "     rm -rf $fmriprepdir/fmriprep_wf/*${SUBJECT[$i]}*\n",
    "     qsub $script/*${SUBJECT[$i]}*\n",
    "  fi\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "fmriprepdir=/Shared/tientong_scratch/abcd/derivatives/fmriprep\n",
    "script=/Shared/tientong_scratch/abcd/code/fmriprep/subject_scripts\n",
    "logdir=/Shared/tientong_scratch/abcd/code/derivative_logs/fmriprep\n",
    "\n",
    "cd $logdir\n",
    "STR1=$'Traceback (most recent call last)'\n",
    "STR2=$'Could not generate CITATION.'\n",
    "log_w_err=($(grep -l \"$STR1\\|$STR2\" `ls ${logdir}`))\n",
    "\n",
    "grep -l \"$STR1\\|$STR2\" `ls ${logdir}` | wc -l\n",
    "\n",
    "for i in ${!log_w_err[@]} ; do\n",
    " SUBJECT=`echo ${log_w_err[$i]} | awk '{gsub(\"_\",\" \"); print $1}' | \n",
    "           awk '{gsub(\"-\",\" \"); print $2}'`\n",
    " rm -rf $fmriprepdir/fmriprep/*$SUBJECT*\n",
    " rm -rf $fmriprepdir/fmriprep_wf/*$SUBJECT*\n",
    " rm -rf $logdir/*$SUBJECT*\n",
    " #qsub $script/*$SUBJECT*\n",
    "done\n",
    "\n",
    "cd\n",
    "\n",
    "\n",
    "for i in ${!log_w_err[@]} ; do\n",
    " SUBJECT=`echo ${log_w_err[$i]} | awk '{gsub(\"_\",\" \"); print $1}' | \n",
    "           awk '{gsub(\"-\",\" \"); print $2}'`\n",
    " rm -rf $fmriprepdir/fmriprep/*$SUBJECT*\n",
    " rm -rf $logdir/*$SUBJECT*\n",
    " sed -e \"s|SUBJECT|${SUBJECT}|g\" ${template}/delete.sh > ${template}/sub-${SUBJECT}_delete.sh\n",
    " qsub ${template}/sub-${SUBJECT}_delete.sh  \n",
    " #qsub $script/*$SUBJECT*\n",
    "done\n",
    "\n",
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fMRIPrep finished successfully!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDARINV73J1L7TG - only have 10s of data??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grep -l \"No errors to report\" `ls fmriprep/*.html` | wc -l\n",
    "\n",
    "grep -r code/derivative_logs/fmriprep \\\n",
    "     -e \"fMRIPrep finished successfully\" | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "non_steady_state_outlier_XX - columns indicate non-steady state volumes with a single 1 value and 0 elsewhere (i.e., there is one non_steady_state_outlier_XX column per outlier/volume). Source code https://github.com/nipy/nipype/blob/929de3595/nipype/algorithms/confounds.py#L974-L995\n",
    "\n",
    "ChrisGorgolewski\n",
    "\n",
    "    Another is adding the artefact regressors produced by FMRIPREP to your GLM. This will essentially remove any variance associated with those scans which could otherwise lead to false results.\n",
    "\n",
    "\n",
    "Additionally, a set of physiological regressors were extracted to allow for component-based noise correction (CompCor, Behzadi et al. 2007). Principal components are estimated after high-pass filtering the preprocessed BOLD time-series **(using a discrete cosine filter with 128s cut-off = 0.008 Hz)** for the two CompCor variants: temporal (tCompCor) and anatomical (aCompCor). tCompCor components are then calculated from the top 5% variable voxels within a mask covering the subcortical regions. This subcortical mask is obtained by heavily eroding the brain mask, which ensures it does not include cortical GM regions. For aCompCor, components are calculated within the intersection of the aforementioned mask and the union of CSF and WM masks calculated in T1w space, after their projection to the native space of each functional run (using the inverse BOLD-to-T1w transformation). Components are also calculated separately within the WM and CSF masks. For each CompCor decomposition, the k components with the largest singular values are retained, such that the retained componentsâ€™ time series are sufficient to explain 50 percent of variance across the nuisance mask (CSF, WM, combined, or temporal). The remaining components are dropped from consideration.\n",
    "\n",
    "fMRIPrep does high-pass filtering before running anatomical or temporal CompCor. Therefore, when using CompCor regressors, the corresponding cosine_XX regressors should also be included in the design matrix.\n",
    "\n",
    "\n",
    "# Notes on Discrete cosine-basis regressors\n",
    "\n",
    "Discrete cosine-basis regressors. Physiological and instrumental (scanner) noise sources are generally present in fMRI data, typically taking the form of low-frequency signal drifts. To account for these drifts, temporal high-pass filtering is the immediate option. Alternatively, low-frequency regressors can be included in the statistical model to account for these confounding signals. Using the DCT basis functions, fMRIPrep generates these low-frequency predictors:\n",
    "\n",
    "cosine_XX - DCT-basis regressors.\n",
    "\n",
    "One characteristic of the cosine regressors is that they are identical for two different datasets with the same TR and the same effective number of time points (effective length). It is relevant to mention effective because initial time points identified as nonsteady states are removed before generating the cosine regressors.\n",
    "\n",
    "\n",
    "Chris Markiewicz:\n",
    "\n",
    "    I mean the regressors are calculated purely from the repetition time (1/sampling rate) and the number of samples, and not at all from the actual values in your data files. Thus, if you have a 1.5s TR and 400 volumes for any two files, the cosine_xx regressors will be identical.\n",
    "\n",
    "    You can also calculate them directly: https://github.com/nipy/nipype/blob/63e5ef25eeaf8717ef271cc3397b41c2e754c5ef/nipype/algorithms/confounds.py#L1489-L1522\n",
    "\n",
    "    The reason we're producing cosine regressors is that we do high-pass filtering before running a/tCompCor, and these are all calculated on the series without non-steady-state volumes. So if you include CompCor regressors, you should also include cosine regressors.\n",
    "\n",
    "\n",
    "\n",
    "Hagler et al. 2019 Neuroimage\n",
    "\n",
    "A total of 16 initial frames (12.8 s) are discarded. On Siemens and Philips scanners, the first eight frames make up the pre-scan reference, and are not saved as DICOMS. An additional eight frames are discarded as part of the pre-analysis processing, for a total of 16 initial frames. \n",
    "\n",
    "On GE scanners with soft-ware version DV25, the first 12 frames make up the pre-scan reference. Instead of being discarded, those 12 reference scans are combined into one, and saved as the first frame, for a total of five initial frames to be discarded as part of the pre-analysis processing for GE DV25 series. \n",
    "\n",
    "On GE scanners with software version DV26, the pre-scan reference is not retained at all, and a total of 16 initial frames are discarded for GE DV26 scans as part of the pre-analysis processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmriprep=\"/Shared/tientong_scratch/abcd/derivatives/fmriprep/fmriprep/\"\n",
    "sub=\"sub-NDARINVT345WWLE\"\n",
    "ses=\"ses-baselineYear1Arm1\"\n",
    "\n",
    "jsonlist=glob.glob(fmriprep + sub + \"/\" + ses +\n",
    "                   \"/func/*_desc-confounds_regressors.json\")\n",
    "\n",
    "\n",
    "test = pd.read_json(jsonlist[2]).T.sort_values(by=['Mask','SingularValue'],\n",
    "                                       ascending=False)\n",
    "\n",
    "test.to_csv(fmriprep + sub + \"/\" + ses + \"/func/\" + 'test.csv', \n",
    "            sep='\\t', index = True, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# create a file of non-steady state counts\n",
    "\n",
    "list=($(ls /Shared/tientong_scratch/abcd/derivatives/fmriprep/fmriprep/*.html))\n",
    "for i in ${!list[@]} ; do\n",
    "sub=$(cut -d \".\" -f 1 <<<`echo ${list[$i]} | awk '{gsub(\"/\",\" \") ; print $7}'`)\n",
    "/Shared/tientong_scratch/abcd/code/postfMRIPrep_misc_count-nonsteady.R \\\n",
    " --path_fmriprep /Shared/tientong_scratch/abcd/derivatives/fmriprep/fmriprep/ \\\n",
    " --subject $sub \\\n",
    " --visit ses-baselineYear1Arm1 \\\n",
    " --output /Shared/tientong_scratch/abcd/derivatives/fmriprep/count_nonsteady.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to load pklz files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from nipype.utils.filemanip import loadpkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file='/Shared/tientong_scratch/abcd/derivatives/fmriprep/fmriprep_wf/single_subject_NDARINV1M0VVR9Y_wf/func_preproc_ses_baselineYear1Arm1_task_rest_run_01_wf/bold_std_trans_wf/bold_reference_wf/enhance_and_skullstrip_bold_wf/_std_target_MNI152NLin2009cAsym./unifize/result_unifize.pklz'\n",
    "res=loadpkl(file)\n",
    "print(res.inputs)\n",
    "print('\\n')\n",
    "print(res.interface)\n",
    "print('\\n')\n",
    "print(res.outputs)\n",
    "print('\\n')\n",
    "print(res.runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
